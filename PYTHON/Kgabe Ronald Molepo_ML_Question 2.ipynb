{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745950a5",
   "metadata": {},
   "source": [
    "# BRCA Subtype Prediction Examination Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac07734",
   "metadata": {},
   "source": [
    "\n",
    "-----------------------------------------\n",
    "Instructions:\n",
    "\n",
    "This exam assesses your knowledge of supervised learning and model evaluation.\n",
    "You are required to predict BRCA subtypes using gene expression data filtered to PAM50 genes.\n",
    "Complete all tasks below and ensure that your code is well-commented and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931511f",
   "metadata": {},
   "source": [
    "# Preloaded Packages (Do NOT modify this section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a826ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299d6a8",
   "metadata": {},
   "source": [
    "# Section 0: Load the Required Data [0 marks - Already provided]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaa6db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is is the size of the data : (1082, 49)\n",
      "\n",
      "Number of samples if each subtype category : SUBTYPE\n",
      "BRCA-LumA      499\n",
      "BRCA-LumB      197\n",
      "BRCA-Basal     171\n",
      "BRCA-Her2       78\n",
      "BRCA-Normal     36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Here is the header of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>SUBTYPE</th>\n",
       "      <th>ACTR3B</th>\n",
       "      <th>ANLN</th>\n",
       "      <th>BAG1</th>\n",
       "      <th>BCL2</th>\n",
       "      <th>BLVRA</th>\n",
       "      <th>CCNB1</th>\n",
       "      <th>CCNE1</th>\n",
       "      <th>CDC20</th>\n",
       "      <th>...</th>\n",
       "      <th>PHGDH</th>\n",
       "      <th>PTTG1</th>\n",
       "      <th>RRM2</th>\n",
       "      <th>SFRP1</th>\n",
       "      <th>SLC39A6</th>\n",
       "      <th>TMEM45B</th>\n",
       "      <th>TYMS</th>\n",
       "      <th>TYRP1</th>\n",
       "      <th>UBE2C</th>\n",
       "      <th>UBE2T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-3C-AAAU</td>\n",
       "      <td>BRCA-LumA</td>\n",
       "      <td>359.824</td>\n",
       "      <td>828.215</td>\n",
       "      <td>1890.570</td>\n",
       "      <td>2315.760</td>\n",
       "      <td>850.618</td>\n",
       "      <td>1282.820</td>\n",
       "      <td>163.3680</td>\n",
       "      <td>603.153</td>\n",
       "      <td>...</td>\n",
       "      <td>741.361</td>\n",
       "      <td>383.605</td>\n",
       "      <td>1477.210</td>\n",
       "      <td>473.2170</td>\n",
       "      <td>90765.90</td>\n",
       "      <td>2.4126</td>\n",
       "      <td>493.114</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>555.590</td>\n",
       "      <td>318.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-3C-AALI</td>\n",
       "      <td>BRCA-Her2</td>\n",
       "      <td>144.644</td>\n",
       "      <td>1566.070</td>\n",
       "      <td>728.026</td>\n",
       "      <td>264.818</td>\n",
       "      <td>1873.300</td>\n",
       "      <td>1877.650</td>\n",
       "      <td>227.8410</td>\n",
       "      <td>648.722</td>\n",
       "      <td>...</td>\n",
       "      <td>759.652</td>\n",
       "      <td>553.018</td>\n",
       "      <td>3219.140</td>\n",
       "      <td>101.6860</td>\n",
       "      <td>1699.29</td>\n",
       "      <td>799.3470</td>\n",
       "      <td>719.320</td>\n",
       "      <td>116.3680</td>\n",
       "      <td>1351.280</td>\n",
       "      <td>1004.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-3C-AALJ</td>\n",
       "      <td>BRCA-LumB</td>\n",
       "      <td>153.219</td>\n",
       "      <td>637.353</td>\n",
       "      <td>1869.720</td>\n",
       "      <td>2538.530</td>\n",
       "      <td>2153.220</td>\n",
       "      <td>1822.300</td>\n",
       "      <td>178.6040</td>\n",
       "      <td>873.980</td>\n",
       "      <td>...</td>\n",
       "      <td>106.981</td>\n",
       "      <td>802.357</td>\n",
       "      <td>1305.530</td>\n",
       "      <td>67.0898</td>\n",
       "      <td>15816.90</td>\n",
       "      <td>5.4397</td>\n",
       "      <td>667.017</td>\n",
       "      <td>131.4600</td>\n",
       "      <td>1195.830</td>\n",
       "      <td>757.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-3C-AALK</td>\n",
       "      <td>BRCA-LumA</td>\n",
       "      <td>135.292</td>\n",
       "      <td>631.775</td>\n",
       "      <td>1651.160</td>\n",
       "      <td>2172.110</td>\n",
       "      <td>1327.270</td>\n",
       "      <td>827.058</td>\n",
       "      <td>44.2698</td>\n",
       "      <td>539.098</td>\n",
       "      <td>...</td>\n",
       "      <td>694.663</td>\n",
       "      <td>311.957</td>\n",
       "      <td>909.392</td>\n",
       "      <td>1236.6600</td>\n",
       "      <td>19032.70</td>\n",
       "      <td>532.4780</td>\n",
       "      <td>724.692</td>\n",
       "      <td>2.0687</td>\n",
       "      <td>496.897</td>\n",
       "      <td>373.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-4H-AAAK</td>\n",
       "      <td>BRCA-LumA</td>\n",
       "      <td>235.319</td>\n",
       "      <td>359.575</td>\n",
       "      <td>2154.500</td>\n",
       "      <td>1575.320</td>\n",
       "      <td>651.064</td>\n",
       "      <td>647.660</td>\n",
       "      <td>56.5957</td>\n",
       "      <td>389.362</td>\n",
       "      <td>...</td>\n",
       "      <td>626.383</td>\n",
       "      <td>257.872</td>\n",
       "      <td>384.255</td>\n",
       "      <td>1531.9100</td>\n",
       "      <td>3834.89</td>\n",
       "      <td>385.1060</td>\n",
       "      <td>675.723</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>322.128</td>\n",
       "      <td>192.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PATIENT_ID    SUBTYPE   ACTR3B      ANLN      BAG1      BCL2     BLVRA  \\\n",
       "0  TCGA-3C-AAAU  BRCA-LumA  359.824   828.215  1890.570  2315.760   850.618   \n",
       "1  TCGA-3C-AALI  BRCA-Her2  144.644  1566.070   728.026   264.818  1873.300   \n",
       "2  TCGA-3C-AALJ  BRCA-LumB  153.219   637.353  1869.720  2538.530  2153.220   \n",
       "3  TCGA-3C-AALK  BRCA-LumA  135.292   631.775  1651.160  2172.110  1327.270   \n",
       "4  TCGA-4H-AAAK  BRCA-LumA  235.319   359.575  2154.500  1575.320   651.064   \n",
       "\n",
       "      CCNB1     CCNE1    CDC20  ...    PHGDH    PTTG1      RRM2      SFRP1  \\\n",
       "0  1282.820  163.3680  603.153  ...  741.361  383.605  1477.210   473.2170   \n",
       "1  1877.650  227.8410  648.722  ...  759.652  553.018  3219.140   101.6860   \n",
       "2  1822.300  178.6040  873.980  ...  106.981  802.357  1305.530    67.0898   \n",
       "3   827.058   44.2698  539.098  ...  694.663  311.957   909.392  1236.6600   \n",
       "4   647.660   56.5957  389.362  ...  626.383  257.872   384.255  1531.9100   \n",
       "\n",
       "    SLC39A6   TMEM45B     TYMS     TYRP1     UBE2C     UBE2T  \n",
       "0  90765.90    2.4126  493.114    1.0340   555.590   318.465  \n",
       "1   1699.29  799.3470  719.320  116.3680  1351.280  1004.350  \n",
       "2  15816.90    5.4397  667.017  131.4600  1195.830   757.026  \n",
       "3  19032.70  532.4780  724.692    2.0687   496.897   373.190  \n",
       "4   3834.89  385.1060  675.723    0.8511   322.128   192.340  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the clinical information\n",
    "clinical_file = 'brca_tcga_data_clinical_patient.txt'\n",
    "clinical_df = pd.read_csv(clinical_file, sep='\\t', skiprows=4)\n",
    "clinical_df.head()\n",
    "\n",
    "# Step 2: Load the mRNA expression (median values)\n",
    "mrna_file = 'brca_tcga_data_RNA_Seq_v2_expression_median.txt'\n",
    "mrna_df = pd.read_csv(mrna_file, sep='\\t')\n",
    "\n",
    "# Remove the Entrez_Gene_Id column if it exists\n",
    "if 'Entrez_Gene_Id' in mrna_df.columns:\n",
    "    mrna_df.drop(columns=['Entrez_Gene_Id'], inplace=True)\n",
    "\n",
    "# Step 3: Load the PAM50 genes\n",
    "pam50_df = pd.read_csv('PAM50_genes.txt')\n",
    "\n",
    "# Step 4: Filter mRNA data to include only PAM50 genes\n",
    "mrna_df = mrna_df[mrna_df['Hugo_Symbol'].isin(pam50_df['Hugo_Symbol'])]\n",
    "\n",
    "# Step 5: Reshape mRNA data so that each row is a patient and each column is a gene\n",
    "mrna_long = mrna_df.set_index('Hugo_Symbol').T.reset_index()\n",
    "mrna_long = mrna_long.rename(columns={'index': 'PATIENT_ID'})\n",
    "\n",
    "# Step 6: Clean PATIENT_IDs for consistency\n",
    "mrna_long['PATIENT_ID'] = mrna_long['PATIENT_ID'].str.replace('_', '-', regex=False).str[:12]\n",
    "clinical_df['PATIENT_ID'] = clinical_df['PATIENT_ID'].str.replace('_', '-', regex=False)\n",
    "\n",
    "# Step 7: Merge clinical data with mRNA expression data\n",
    "clinical_subset = clinical_df[['PATIENT_ID', 'SUBTYPE']]\n",
    "data = pd.merge(clinical_subset, mrna_long, on='PATIENT_ID', how='inner')\n",
    "\n",
    "# Step 8: Remove samples with NA subtype and clean labels\n",
    "data = data[data['SUBTYPE'] != 'NA']\n",
    "data['SUBTYPE'] = data['SUBTYPE'].str.replace('_', '-', regex=False)\n",
    "data['SUBTYPE'] = data['SUBTYPE'].astype('category')\n",
    "\n",
    "# Display the shapes of the datasets to understand their dimensions\n",
    "print(\"This is is the size of the data :\", data.shape)  # Shape of the training data\n",
    "\n",
    "# check the number of samples in each category \n",
    "print(\"\\nNumber of samples if each subtype category :\", data['SUBTYPE'].value_counts())\n",
    "\n",
    "# the size of the data \n",
    "print(\"\\nHere is the header of the data:\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a58b2",
   "metadata": {},
   "source": [
    "# Section 1: Prepare the Dataset [6 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a6dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 101 NaN values in target variable, removing these rows\n",
      "\n",
      "Training set class distribution:\n",
      "SUBTYPE\n",
      "BRCA-LumA      349\n",
      "BRCA-LumB      138\n",
      "BRCA-Basal     120\n",
      "BRCA-Her2       54\n",
      "BRCA-Normal     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      "SUBTYPE\n",
      "BRCA-LumA      150\n",
      "BRCA-LumB       59\n",
      "BRCA-Basal      51\n",
      "BRCA-Her2       24\n",
      "BRCA-Normal     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training set size: 686\n",
      "Test set size: 295\n"
     ]
    }
   ],
   "source": [
    "# Task:\n",
    "# Q1. Extract gene expression features and subtype labels from the merged dataset. [1 mark]\n",
    "# Q2. Standardize the gene expression features using Z-score normalization. [2 marks]\n",
    "# Q3. Split the dataset into training and test sets using a 70/30 stratified split. [2 mark]\n",
    "# Q4. Report the number of instances in each class in both training and test sets. [1 mark]\n",
    "\n",
    "# ****** write your code here *******\n",
    "# Q1. Extract gene expression features and subtype labels from the merged dataset.\n",
    "X = data.drop(columns=['PATIENT_ID', 'SUBTYPE'])  # Gene expression features\n",
    "y = data['SUBTYPE']  # Subtype labels\n",
    "\n",
    "# Check for NaN in target variable and remove those rows\n",
    "nan_mask = y.isna()\n",
    "if nan_mask.any():\n",
    "    print(f\"Warning: Found {nan_mask.sum()} NaN values in target variable, removing these rows\")\n",
    "    X = X[~nan_mask]\n",
    "    y = y[~nan_mask]\n",
    "\n",
    "# Q2. Standardize the gene expression features using Z-score normalization.\n",
    "# Also handle potential NaN in features by filling with mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Fill NaN with mean of the column\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_imputed = imputer.fit_transform(X)  # First handle missing values\n",
    "X_scaled = scaler.fit_transform(X_imputed)  # Then standardize\n",
    "\n",
    "# Q3. Split the dataset into training and test sets using a 70/30 stratified split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, \n",
    "                                                    stratify=y, random_state=42)\n",
    "\n",
    "# Q4. Report the number of instances in each class in both training and test sets.\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# ***********************************\n",
    "\n",
    "# Write you comment here on the number of instances in each class and the size of the training / test set: \n",
    "# Your explanation here: Training set size: 686; Test set size: 295"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226415e",
   "metadata": {},
   "source": [
    "# Section 2: Train Statistical Learning Models [8 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc31f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and evaluating Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Accuracy: 0.8712\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1   0   0   0]\n",
      " [  0  20   2   2   0]\n",
      " [  0   2 141   7   0]\n",
      " [  0   2  13  43   1]\n",
      " [  1   0   7   0   3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       0.98      0.98      0.98        51\n",
      "   BRCA-Her2       0.80      0.83      0.82        24\n",
      "   BRCA-LumA       0.87      0.94      0.90       150\n",
      "   BRCA-LumB       0.83      0.73      0.77        59\n",
      " BRCA-Normal       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.87       295\n",
      "   macro avg       0.84      0.75      0.77       295\n",
      "weighted avg       0.87      0.87      0.86       295\n",
      "\n",
      "AUC (OvR): 0.9774\n",
      "\n",
      "==================================================\n",
      "Training and evaluating Random Forest\n",
      "==================================================\n",
      "\n",
      "Accuracy: 0.8915\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   0   0   0   0]\n",
      " [  0  20   3   1   0]\n",
      " [  0   0 147   3   0]\n",
      " [  0   0  16  43   0]\n",
      " [  0   0   9   0   2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       1.00      1.00      1.00        51\n",
      "   BRCA-Her2       1.00      0.83      0.91        24\n",
      "   BRCA-LumA       0.84      0.98      0.90       150\n",
      "   BRCA-LumB       0.91      0.73      0.81        59\n",
      " BRCA-Normal       1.00      0.18      0.31        11\n",
      "\n",
      "    accuracy                           0.89       295\n",
      "   macro avg       0.95      0.74      0.79       295\n",
      "weighted avg       0.90      0.89      0.88       295\n",
      "\n",
      "AUC (OvR): 0.9881\n",
      "\n",
      "==================================================\n",
      "Training and evaluating SVM\n",
      "==================================================\n",
      "\n",
      "Accuracy: 0.8271\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1   0   0   0]\n",
      " [  2  17   2   3   0]\n",
      " [  0   1 141   7   1]\n",
      " [  4   4  18  33   0]\n",
      " [  3   0   5   0   3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       0.85      0.98      0.91        51\n",
      "   BRCA-Her2       0.74      0.71      0.72        24\n",
      "   BRCA-LumA       0.85      0.94      0.89       150\n",
      "   BRCA-LumB       0.77      0.56      0.65        59\n",
      " BRCA-Normal       0.75      0.27      0.40        11\n",
      "\n",
      "    accuracy                           0.83       295\n",
      "   macro avg       0.79      0.69      0.71       295\n",
      "weighted avg       0.82      0.83      0.81       295\n",
      "\n",
      "AUC (OvR): 0.9651\n",
      "\n",
      "\n",
      "Model Comparison:\n",
      "Model                Accuracy   AUC       \n",
      "----------------------------------------\n",
      "Logistic Regression  0.8712     0.9774    \n",
      "Random Forest        0.8915     0.9881    \n",
      "SVM                  0.8271     0.9651    \n"
     ]
    }
   ],
   "source": [
    "# Task:\n",
    "# - Train three different classifiers (e.g., Logistic Regression, Random Forest, SVM). [3 marks]\n",
    "# - Evaluate each using accuracy, confusion matrix, classification report, and AUC. [3 marks]\n",
    "# - Summarize and compare the performance. [2 marks]\n",
    "\n",
    "# ****** write your code here *******\n",
    "# Initialize classifiers\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42)  # probability=True for AUC calculation\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training and evaluating {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # AUC (One-vs-Rest for multiclass)\n",
    "    if y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "        print(f\"AUC (OvR): {auc_score:.4f}\")\n",
    "    else:\n",
    "        auc_score = None\n",
    "        print(\"AUC not available (model doesn't support probability estimates)\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': classification_report(y_test, y_pred, output_dict=True),\n",
    "        'auc': auc_score\n",
    "    }\n",
    "\n",
    "# Compare model performance\n",
    "print(\"\\n\\nModel Comparison:\")\n",
    "print(\"{:<20} {:<10} {:<10}\".format(\"Model\", \"Accuracy\", \"AUC\"))\n",
    "print(\"-\"*40)\n",
    "for name, res in results.items():\n",
    "    print(\"{:<20} {:<10.4f} {:<10.4f}\".format(\n",
    "        name, \n",
    "        res['accuracy'], \n",
    "        res['auc'] if res['auc'] is not None else float('nan')\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "# ***********************************\n",
    "\n",
    "# Your comment here on the performance of the models:Random Forest performed best (89.2% accuracy, 0.988 AUC) but struggled with rare subtypes. Logistic Regression balanced accuracy (87.1%) and interpretability, while SVM trailed (82.7%) but maintained decent AUC (0.965). \n",
    "#All excelled at identifying BRCA-Basal (98-100% recall) but performed poorly on BRCA-Normal. Random Forest is ideal for clinical use, Logistic Regression for interpretable research, and SVM may improve with tuning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051f2967",
   "metadata": {},
   "source": [
    "# Section 3: Train Neural Network Models [16 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c640a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronal\\py312_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Shallow Network\n",
      "==================================================\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 182ms/step - accuracy: 0.4252 - loss: 1.3644 - val_accuracy: 0.6232 - val_loss: 1.0631\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.7251 - loss: 0.8500 - val_accuracy: 0.6884 - val_loss: 0.8533\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7671 - loss: 0.6934 - val_accuracy: 0.7391 - val_loss: 0.7299\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8030 - loss: 0.5757 - val_accuracy: 0.7754 - val_loss: 0.6564\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.8121 - loss: 0.5130 - val_accuracy: 0.8043 - val_loss: 0.5978\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.8414 - loss: 0.4752 - val_accuracy: 0.8043 - val_loss: 0.5617\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8519 - loss: 0.4192 - val_accuracy: 0.8116 - val_loss: 0.5388\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8549 - loss: 0.3881 - val_accuracy: 0.8043 - val_loss: 0.5240\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8665 - loss: 0.3482 - val_accuracy: 0.8116 - val_loss: 0.5153\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8854 - loss: 0.3464 - val_accuracy: 0.8116 - val_loss: 0.5011\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.8604 - loss: 0.3387 - val_accuracy: 0.8116 - val_loss: 0.4928\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8753 - loss: 0.3479 - val_accuracy: 0.8116 - val_loss: 0.4772\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8939 - loss: 0.3091 - val_accuracy: 0.8116 - val_loss: 0.4779\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8965 - loss: 0.2953 - val_accuracy: 0.8116 - val_loss: 0.4726\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8983 - loss: 0.2702 - val_accuracy: 0.8188 - val_loss: 0.4640\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8819 - loss: 0.3117 - val_accuracy: 0.8188 - val_loss: 0.4630\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8845 - loss: 0.3000 - val_accuracy: 0.8188 - val_loss: 0.4594\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8881 - loss: 0.2797 - val_accuracy: 0.8188 - val_loss: 0.4468\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.8917 - loss: 0.2804 - val_accuracy: 0.8188 - val_loss: 0.4504\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9199 - loss: 0.2453 - val_accuracy: 0.8188 - val_loss: 0.4497\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.9061 - loss: 0.2660 - val_accuracy: 0.8188 - val_loss: 0.4525\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9025 - loss: 0.2394 - val_accuracy: 0.8261 - val_loss: 0.4510\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.8878 - loss: 0.2670 - val_accuracy: 0.8261 - val_loss: 0.4561\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9151 - loss: 0.2392 - val_accuracy: 0.8333 - val_loss: 0.4491\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9202 - loss: 0.2395 - val_accuracy: 0.8333 - val_loss: 0.4451\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9209 - loss: 0.2213 - val_accuracy: 0.8261 - val_loss: 0.4448\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8803 - loss: 0.2514 - val_accuracy: 0.8406 - val_loss: 0.4427\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.9281 - loss: 0.2176 - val_accuracy: 0.8406 - val_loss: 0.4439\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9264 - loss: 0.2055 - val_accuracy: 0.8333 - val_loss: 0.4296\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9394 - loss: 0.2023 - val_accuracy: 0.8406 - val_loss: 0.4365\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9249 - loss: 0.2081 - val_accuracy: 0.8406 - val_loss: 0.4349\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9097 - loss: 0.2348 - val_accuracy: 0.8406 - val_loss: 0.4340\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9093 - loss: 0.2019 - val_accuracy: 0.8406 - val_loss: 0.4366\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9409 - loss: 0.1727 - val_accuracy: 0.8333 - val_loss: 0.4389\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9275 - loss: 0.1819 - val_accuracy: 0.8333 - val_loss: 0.4342\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9254 - loss: 0.1993 - val_accuracy: 0.8406 - val_loss: 0.4360\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9329 - loss: 0.1784 - val_accuracy: 0.8478 - val_loss: 0.4341\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9380 - loss: 0.1859 - val_accuracy: 0.8478 - val_loss: 0.4365\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9351 - loss: 0.1608 - val_accuracy: 0.8333 - val_loss: 0.4412\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       0.96      1.00      0.98        51\n",
      "   BRCA-Her2       0.80      0.67      0.73        24\n",
      "   BRCA-LumA       0.86      0.93      0.89       150\n",
      "   BRCA-LumB       0.73      0.68      0.70        59\n",
      " BRCA-Normal       1.00      0.55      0.71        11\n",
      "\n",
      "    accuracy                           0.85       295\n",
      "   macro avg       0.87      0.76      0.80       295\n",
      "weighted avg       0.85      0.85      0.85       295\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 51   0   0   0   0]\n",
      " [  1  16   2   5   0]\n",
      " [  0   1 139  10   0]\n",
      " [  1   3  15  40   0]\n",
      " [  0   0   5   0   6]]\n",
      "\n",
      "AUC: 0.9657\n",
      "\n",
      "==================================================\n",
      "Training Medium Network\n",
      "==================================================\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 126ms/step - accuracy: 0.2152 - loss: 2.3069 - val_accuracy: 0.6449 - val_loss: 1.1537\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.6689 - loss: 0.9356 - val_accuracy: 0.7319 - val_loss: 0.8927\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 289ms/step - accuracy: 0.7954 - loss: 0.6300 - val_accuracy: 0.7899 - val_loss: 0.7576\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.8138 - loss: 0.5468 - val_accuracy: 0.8188 - val_loss: 0.6730\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8209 - loss: 0.4582 - val_accuracy: 0.8333 - val_loss: 0.6187\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.8391 - loss: 0.4342 - val_accuracy: 0.8333 - val_loss: 0.5712\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.8326 - loss: 0.4050 - val_accuracy: 0.8261 - val_loss: 0.5342\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8491 - loss: 0.3903 - val_accuracy: 0.8261 - val_loss: 0.5024\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.8312 - loss: 0.3469 - val_accuracy: 0.8406 - val_loss: 0.4763\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.8471 - loss: 0.3606 - val_accuracy: 0.8406 - val_loss: 0.4692\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8992 - loss: 0.3050 - val_accuracy: 0.8406 - val_loss: 0.4570\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.8517 - loss: 0.3985 - val_accuracy: 0.8261 - val_loss: 0.4627\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.8743 - loss: 0.3159 - val_accuracy: 0.8261 - val_loss: 0.4524\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.8742 - loss: 0.3069 - val_accuracy: 0.8261 - val_loss: 0.4546\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.8872 - loss: 0.2755 - val_accuracy: 0.8406 - val_loss: 0.4525\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8726 - loss: 0.3010 - val_accuracy: 0.8406 - val_loss: 0.4430\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9100 - loss: 0.2337 - val_accuracy: 0.8333 - val_loss: 0.4447\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8807 - loss: 0.3323 - val_accuracy: 0.8333 - val_loss: 0.4356\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8990 - loss: 0.3030 - val_accuracy: 0.8406 - val_loss: 0.4420\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9063 - loss: 0.2561 - val_accuracy: 0.8478 - val_loss: 0.4468\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9054 - loss: 0.2517 - val_accuracy: 0.8261 - val_loss: 0.4461\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9079 - loss: 0.2348 - val_accuracy: 0.8261 - val_loss: 0.4497\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9221 - loss: 0.2205 - val_accuracy: 0.8261 - val_loss: 0.4573\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.8974 - loss: 0.2145 - val_accuracy: 0.8261 - val_loss: 0.4805\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9142 - loss: 0.2065 - val_accuracy: 0.8188 - val_loss: 0.4948\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9263 - loss: 0.2214 - val_accuracy: 0.8261 - val_loss: 0.4829\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9052 - loss: 0.2111 - val_accuracy: 0.8261 - val_loss: 0.4915\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9052 - loss: 0.2305 - val_accuracy: 0.8333 - val_loss: 0.4858\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       0.94      0.98      0.96        51\n",
      "   BRCA-Her2       0.78      0.75      0.77        24\n",
      "   BRCA-LumA       0.86      0.93      0.90       150\n",
      "   BRCA-LumB       0.77      0.69      0.73        59\n",
      " BRCA-Normal       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.86       295\n",
      "   macro avg       0.87      0.74      0.78       295\n",
      "weighted avg       0.86      0.86      0.85       295\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 50   1   0   0   0]\n",
      " [  1  18   2   3   0]\n",
      " [  0   1 140   9   0]\n",
      " [  1   3  14  41   0]\n",
      " [  1   0   6   0   4]]\n",
      "\n",
      "AUC: 0.9756\n",
      "\n",
      "==================================================\n",
      "Training Deep Network\n",
      "==================================================\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 164ms/step - accuracy: 0.2479 - loss: 1.9992 - val_accuracy: 0.6522 - val_loss: 1.1597\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.7118 - loss: 0.8119 - val_accuracy: 0.7464 - val_loss: 0.9102\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.7767 - loss: 0.5876 - val_accuracy: 0.7971 - val_loss: 0.7761\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.8274 - loss: 0.4857 - val_accuracy: 0.8116 - val_loss: 0.6767\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.8176 - loss: 0.4629 - val_accuracy: 0.8333 - val_loss: 0.6037\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 273ms/step - accuracy: 0.8464 - loss: 0.4221 - val_accuracy: 0.8261 - val_loss: 0.5526\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.8635 - loss: 0.3891 - val_accuracy: 0.8261 - val_loss: 0.5289\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.8714 - loss: 0.3368 - val_accuracy: 0.8188 - val_loss: 0.5001\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.8612 - loss: 0.3039 - val_accuracy: 0.8406 - val_loss: 0.4897\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.8582 - loss: 0.4322 - val_accuracy: 0.8478 - val_loss: 0.4685\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.8295 - loss: 0.4167 - val_accuracy: 0.8333 - val_loss: 0.4596\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8790 - loss: 0.3015 - val_accuracy: 0.8261 - val_loss: 0.4681\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.8591 - loss: 0.3446 - val_accuracy: 0.8261 - val_loss: 0.4569\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8762 - loss: 0.3241 - val_accuracy: 0.8261 - val_loss: 0.4572\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8694 - loss: 0.3416 - val_accuracy: 0.8333 - val_loss: 0.4870\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.8626 - loss: 0.3078 - val_accuracy: 0.8188 - val_loss: 0.4767\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.8966 - loss: 0.3009 - val_accuracy: 0.8116 - val_loss: 0.4753\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8847 - loss: 0.3178 - val_accuracy: 0.8188 - val_loss: 0.4883\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8930 - loss: 0.2589 - val_accuracy: 0.8261 - val_loss: 0.4954\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9085 - loss: 0.2478 - val_accuracy: 0.8261 - val_loss: 0.5017\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.8887 - loss: 0.2607 - val_accuracy: 0.8043 - val_loss: 0.4871\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.8846 - loss: 0.2978 - val_accuracy: 0.8261 - val_loss: 0.4801\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.8837 - loss: 0.2895 - val_accuracy: 0.8188 - val_loss: 0.4971\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BRCA-Basal       0.98      0.94      0.96        51\n",
      "   BRCA-Her2       0.70      0.79      0.75        24\n",
      "   BRCA-LumA       0.85      0.92      0.88       150\n",
      "   BRCA-LumB       0.76      0.59      0.67        59\n",
      " BRCA-Normal       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.84       295\n",
      "   macro avg       0.82      0.79      0.80       295\n",
      "weighted avg       0.84      0.84      0.84       295\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48   3   0   0   0]\n",
      " [  1  19   2   2   0]\n",
      " [  0   1 138   9   2]\n",
      " [  0   4  20  35   0]\n",
      " [  0   0   3   0   8]]\n",
      "\n",
      "AUC: 0.9675\n",
      "\n",
      "Model Comparison:\n",
      "Model      Accuracy   AUC       \n",
      "------------------------------\n",
      "Shallow    0.8542     0.9657    \n",
      "Medium     0.8576     0.9756    \n",
      "Deep       0.8407     0.9675    \n"
     ]
    }
   ],
   "source": [
    "# Task:\n",
    "# Q8. Design and train three different neural network architectures: Shallow, Medium, and Deep. [6 marks]\n",
    "# Q9. Evaluate the models on the test set using classification report, confusion matrix, and AUC. [6 marks]\n",
    "# Q10. Compare model performances and discuss the observed trends. [4 marks]\n",
    "\n",
    "# ****** write your code here *******\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# First convert string labels to numerical indices\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Now convert to one-hot encoding\n",
    "y_train_oh = to_categorical(y_train_encoded)\n",
    "y_test_oh = to_categorical(y_test_encoded)\n",
    "\n",
    "# Define architectures\n",
    "models = {\n",
    "    \"Shallow\": Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(y_train_oh.shape[1], activation='softmax')\n",
    "    ]),\n",
    "    \n",
    "    \"Medium\": Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(y_train_oh.shape[1], activation='softmax')\n",
    "    ]),\n",
    "    \n",
    "    \"Deep\": Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(y_train_oh.shape[1], activation='softmax')\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name} Network\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train_oh,\n",
    "                       epochs=100,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       callbacks=[early_stop],\n",
    "                       verbose=1)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Convert back to original labels for reporting\n",
    "    y_pred_labels = label_encoder.inverse_transform(y_pred_class)\n",
    "    y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "    \n",
    "    auc = roc_auc_score(y_test_oh, y_pred, multi_class='ovr')\n",
    "    print(f\"\\nAUC: {auc:.4f}\")\n",
    "    \n",
    "    results[name] = {\n",
    "        'classification_report': classification_report(y_test_labels, y_pred_labels, output_dict=True),\n",
    "        'confusion_matrix': confusion_matrix(y_test_labels, y_pred_labels),\n",
    "        'auc': auc,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "# Compare performance\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(\"{:<10} {:<10} {:<10}\".format(\"Model\", \"Accuracy\", \"AUC\"))\n",
    "print(\"-\"*30)\n",
    "for name, res in results.items():\n",
    "    acc = res['classification_report']['accuracy']\n",
    "    print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, acc, res['auc']))\n",
    "\n",
    "\n",
    "# ***********************************\n",
    "# Your explanation here: The Medium network achieved the highest accuracy (85.76%), slightly outperforming the Shallow (85.42%) and Deep (84.07%) networks, indicating that deeper architectures may yield diminishing returns for this task. \n",
    "    #In terms of training dynamics, the Shallow network trained most stably with minimal divergence between training and validation accuracy, while the Deep network displayed more volatile validation trends. Overfitting was evident in all models, with the Medium network managing it best due to regularization techniques like batch normalization and dropout.\n",
    "    #All models struggled with the rare BRCA-Normal class, but performed well on BRCA-Basal, with the Medium network achieving the most balanced classification. Finally, AUC analysis confirmed the Medium network’s superior discriminative ability (0.9756), although all models showed comparable ranking performance with minor AUC differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993885c",
   "metadata": {},
   "source": [
    "# Final Reflections [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11. Comment on the overall performance of the models trained (statistical and neural networks). [4 marks]\n",
    "# Q12. How did class imbalance affect model training and evaluation metrics? [3 marks]\n",
    "# Q13. Why might certain BRCA subtypes be harder to classify accurately than others? [3 marks]\n",
    "\n",
    "# ****** write your explanation here *******\n",
    "# Q11: All models performed well (85-89% accuracy), with Random Forest and Medium NN performing best. \n",
    "#      Neural networks showed more overfitting than statistical models. Performance was strongest \n",
    "#      for common subtypes (Basal, LumA) across all models.\n",
    "\n",
    "# Q12: Class imbalance hurt recall for rare subtypes (Normal: <55%) despite high precision. \n",
    "#      Statistical models handled imbalance slightly better than NNs. F1-scores revealed this \n",
    "#      weakness better than accuracy alone.\n",
    "\n",
    "# Q13: Harder subtypes (Normal, Her2) likely have: 1) Fewer samples, 2) Overlapping gene expression \n",
    "#      patterns, and/or 3) Higher biological variability. LumB also confused models due to \n",
    "#      intermediate features with LumA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.12)",
   "language": "python",
   "name": "py312_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
